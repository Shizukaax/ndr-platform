# ğŸ›¡ï¸ NDR Platform - Network Detection & Response

[![Python](https://img.shields.io/badge/python-3.11+-blue.svg)](https://www.python.org/downloads/)
[![Streamlit](https://img.shields.io/badge/streamlit-1.28+-brightgreen.svg)](https://streamlit.io/)
[![Docker](https://img.shields.io/badge/docker-ready-blue.svg)](https://www.docker.com/)
[![License](https://img.shields.io/badge/license-MIT-green.svg)](LICENSE)
[![CI/CD](https://img.shields.io/badge/CI%2FCD-GitHub%20Actions-green.svg)](https://github.com/Shizukaax/ndr-platform/actions)
[![Security](https://img.shields.io/badge/security-scanned-brightgreen.svg)](https://github.com/Shizukaax/ndr-platform/security)

**Advanced Network Security Analytics Platform with AI-Powered Threat Detection and MITRE ATT&CK Integration**

**ğŸ‘¨â€ğŸ’» Author:** [Shizukaax](https://github.com/Shizukaax) | **ğŸ”— Repository:** [ndr-platform](https://github.com/Shizukaax/ndr-platform)

## ğŸ¯ Overview

The NDR Platform is an enterprise-grade Network Detection and Response system that leverages machine learning and artificial intelligence to detect, analyze, and respond to network anomalies and security threats. Built with modern web technologies and designed for scalability, it provides comprehensive network security monitoring with automatic threat intelligence mapping.

### âœ¨ Key Features

- **ğŸ¤– AI-Powered Anomaly Detection** - Advanced machine learning algorithms for threat detection
- **ğŸ¯ MITRE ATT&CK Integration** - Automatic mapping to threat techniques and tactics  
- **ğŸ“Š Real-time Analytics** - Live monitoring and analysis of network traffic
- **ğŸ“‹ Comprehensive Reporting** - Automated report generation and export capabilities
- **ğŸ” Interactive Visualizations** - Rich data visualization and exploration tools
- **ğŸ³ Production Ready** - Docker containerization with scalable deployment options

## ğŸš€ Quick Start

### Prerequisites

- **Python 3.11+**
- **Docker & Docker Compose** (for containerized deployment)
- **8GB+ RAM** (recommended for large datasets)

### ğŸ³ Docker Deployment (Recommended)

```bash
# Clone the repository
git clone https://github.com/Shizukaax/ndr-platform.git
cd ndr-platform

# Configure environment
cp .env.example .env
# Edit .env with your configuration

# Start the platform (from deployment directory)
cd deployment
docker-compose up -d

# Access the application
open http://localhost:8501
```

### ğŸ Local Development Setup

```bash
# Clone and setup
git clone https://github.com/Shizukaax/ndr-platform.git
cd ndr-platform

# Create virtual environment
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt

# Setup platform
python scripts/setup.py

# Run the application
streamlit run run.py
```

## ğŸ—ï¸ Architecture

The NDR Platform follows a modular microservices architecture:

```
ğŸ“¦ NDR Platform
â”œâ”€â”€ ğŸ¯ Frontend Layer (Streamlit Web UI)
â”‚   â”œâ”€â”€ Interactive Dashboards
â”‚   â”œâ”€â”€ Real-time Monitoring
â”‚   â””â”€â”€ Report Generation
â”œâ”€â”€ âš™ï¸ Core Services Layer
â”‚   â”œâ”€â”€ Machine Learning Engine
â”‚   â”œâ”€â”€ Data Processing Pipeline
â”‚   â”œâ”€â”€ MITRE ATT&CK Mapper
â”‚   â””â”€â”€ Analytics Engine
â”œâ”€â”€ ğŸ’¾ Data Layer
â”‚   â”œâ”€â”€ Network Data Ingestion
â”‚   â”œâ”€â”€ Model Storage
â”‚   â””â”€â”€ Results Management
â””â”€â”€ ğŸ”§ Infrastructure Layer
    â”œâ”€â”€ Docker Containers
    â”œâ”€â”€ Logging & Monitoring
    â””â”€â”€ Configuration Management
```

### ğŸ§© Core Components

| Component | Purpose | Technology |
|-----------|---------|------------|
| **Detection Engine** | ML-based anomaly detection | Scikit-learn, Isolation Forest |
| **MITRE Mapper** | Threat technique classification | Custom algorithms + MITRE ATT&CK DB |
| **Analytics Dashboard** | Real-time visualization | Streamlit, Plotly |
| **Data Pipeline** | Network data processing | Pandas, NumPy |
| **Report Generator** | Automated reporting | PDF, Excel, JSON export |

## ğŸ› ï¸ Technology Stack

- **Backend**: Python 3.11+, FastAPI
- **Frontend**: Streamlit, Plotly, HTML/CSS
- **Machine Learning**: Scikit-learn, SHAP, LIME
- **Data Processing**: Pandas, NumPy, JSON
- **Deployment**: Docker, Docker Compose
- **Monitoring**: Structured logging, Health checks

## ğŸ“Š Supported Data Formats

- **Primary**: Arkime JSON exports
- **Network Captures**: PCAP (converted to JSON)
- **Log Formats**: Zeek, Suricata, Custom JSON
- **Real-time**: Network streams, API integrations

## ğŸ® Usage Examples

### Basic Anomaly Detection

```python
# Load your network data
python run.py

# 1. Upload data files via the web interface
# 2. Select anomaly detection algorithm
# 3. Configure detection parameters
# 4. Run analysis and review results
```

### API Integration

```python
import requests

# Analyze network data via API
response = requests.post('http://localhost:8501/api/analyze', json={
    'data': network_events,
    'algorithm': 'IsolationForest',
    'threshold': 0.1
})

anomalies = response.json()['anomalies']
```

### Automated Reporting

```bash
# Generate daily security report
curl -X POST "http://localhost:8501/api/reports" \
     -H "Content-Type: application/json" \
     -d '{"type": "daily", "format": "pdf"}'
```

## ğŸ“ˆ Performance & Scale

- **Processing Capacity**: 10M+ network events per hour
- **Real-time Analysis**: <100ms latency for anomaly detection
- **Data Retention**: Configurable (default: 90 days)
- **Concurrent Users**: Supports 50+ simultaneous analysts
- **Memory Usage**: 2-8GB depending on dataset size

## ğŸ” Security Features

- **Data Encryption**: TLS 1.3 for data in transit
- **Access Control**: Role-based permissions
- **Audit Logging**: Complete activity tracking
- **Network Isolation**: Containerized deployment
- **Secure Defaults**: Hardened configuration templates

## ğŸ“š Documentation

Comprehensive documentation is available in the `docs/` directory:

- **[ğŸ“– User Guide](docs/USER_GUIDE.md)** - Complete user manual
- **[ğŸ”§ Configuration Guide](docs/CONFIGURATION_GUIDE.md)** - Setup and configuration
- **[ğŸš€ Deployment Guide](docs/DEPLOYMENT_GUIDE.md)** - Production deployment
- **[ğŸ”— API Documentation](docs/API_DOCUMENTATION.md)** - API reference
- **[ğŸ—ï¸ Project Structure](docs/PROJECT_ORGANIZATION.md)** - Architecture details

## ğŸ¤ Community & Contributing

### **ğŸ“‹ Project Resources**
- **[ğŸ¤ Contributing Guidelines](CONTRIBUTING.md)** - How to contribute
- **[ğŸ†˜ Getting Support](SUPPORT.md)** - Help and troubleshooting
- **[ğŸ”’ Security Policy](SECURITY.md)** - Report security issues
- **[ğŸ’° Sponsor This Project](FUNDING.yml)** - Support development

### **ğŸš€ Quick Contribution**
1. **Fork** the repository
2. **Create** a feature branch
3. **Follow** our [contribution guidelines](CONTRIBUTING.md)
4. **Submit** a pull request

## ğŸ§ª Testing

```bash
# Run the complete test suite
pytest tests/

# Run specific test categories
pytest tests/test_anomaly_detection.py  # ML model tests
pytest tests/test_mitre_mapping.py      # MITRE integration tests
pytest tests/test_api.py                # API endpoint tests

# Performance testing
pytest tests/test_performance.py --benchmark
```

## ğŸš€ Deployment Options

### Development
```bash
streamlit run run.py
```

### Production (Docker)
```bash
cd deployment
docker-compose -f docker-compose.prod.yml up -d
```

### Kubernetes
```bash
kubectl apply -f k8s/
```

### Cloud Deployment
- **AWS**: ECS, EKS, or EC2 with CloudFormation
- **Azure**: Container Instances or AKS
- **GCP**: Cloud Run or GKE

## ğŸ”„ CI/CD Pipeline

The project includes automated CI/CD workflows:

- **Testing**: Automated test execution on pull requests
- **Building**: Docker image builds and registry push
- **Deployment**: Automated staging and production deployments
- **Security**: Vulnerability scanning and dependency updates

## ğŸ¤ Contributing

We welcome contributions! Please see our contribution guidelines:

1. **Fork** the repository
2. **Create** a feature branch (`git checkout -b feature/amazing-feature`)
3. **Commit** your changes (`git commit -m 'Add amazing feature'`)
4. **Push** to the branch (`git push origin feature/amazing-feature`)
5. **Open** a Pull Request

### Development Guidelines

- Follow PEP 8 style guide
- Add tests for new features
- Update documentation
- Ensure all tests pass

## ï¿½ Project Structure

```
ndr-platform/
â”œâ”€â”€ .github/                    # GitHub configuration & workflows
â”‚   â”œâ”€â”€ workflows/ci.yml        # Automated CI/CD pipeline
â”‚   â”œâ”€â”€ README.md               # Main project documentation
â”‚   â”œâ”€â”€ CONTRIBUTING.md         # Contribution guidelines
â”‚   â”œâ”€â”€ SECURITY.md             # Security policy
â”‚   â””â”€â”€ templates/              # Issue & PR templates
â”œâ”€â”€ deployment/                 # Deployment configuration
â”‚   â”œâ”€â”€ docker-compose.yml      # Container orchestration
â”‚   â”œâ”€â”€ Dockerfile              # Application container
â”‚   â”œâ”€â”€ nginx.conf              # Reverse proxy setup
â”‚   â””â”€â”€ README.md               # Deployment guide
â”œâ”€â”€ scripts/                    # Management & utility scripts
â”‚   â”œâ”€â”€ setup.py                # Platform initialization
â”‚   â”œâ”€â”€ deploy.py               # Deployment automation
â”‚   â”œâ”€â”€ health_check.py         # System monitoring
â”‚   â”œâ”€â”€ security_scanner.py     # Security auditing
â”‚   â”œâ”€â”€ model_manager.py        # ML model lifecycle
â”‚   â”œâ”€â”€ data_manager.py         # Data operations
â”‚   â”œâ”€â”€ backup.py               # Backup & restore
â”‚   â”œâ”€â”€ log_analyzer.py         # Log analysis
â”‚   â””â”€â”€ dev_utils.py            # Development tools
â”œâ”€â”€ app/                        # Main application code
â”‚   â”œâ”€â”€ components/             # Reusable UI components
â”‚   â”œâ”€â”€ pages/                  # Streamlit pages
â”‚   â””â”€â”€ state/                  # Session management
â”œâ”€â”€ core/                       # Core business logic
â”‚   â”œâ”€â”€ models/                 # ML model implementations
â”‚   â”œâ”€â”€ explainers/             # Model interpretability
â”‚   â””â”€â”€ *.py                    # Core services
â”œâ”€â”€ docs/                       # Comprehensive documentation
â”œâ”€â”€ examples/                   # Usage examples & tutorials
â”œâ”€â”€ tools/                      # Utility modules
â”œâ”€â”€ data/                       # Data storage
â”‚   â”œâ”€â”€ examples/               # Sample datasets
â”‚   â””â”€â”€ realtime/               # Live data ingestion
â”œâ”€â”€ logs/                       # Application logs
â”œâ”€â”€ models/                     # Trained ML models
â”œâ”€â”€ reports/                    # Generated reports
â”œâ”€â”€ results/                    # Analysis results
â”œâ”€â”€ tests/                      # Test suite
â”œâ”€â”€ CHANGELOG.md               # Version history
â”œâ”€â”€ requirements.txt           # Python dependencies
â””â”€â”€ run.py                     # Application entry point
```

## ğŸ› ï¸ Available Scripts

The platform includes comprehensive management scripts:

| Script | Purpose | Usage |
|--------|---------|-------|
| `setup.py` | Initial platform setup | `python scripts/setup.py` |
| `deploy.py` | Automated deployment | `python scripts/deploy.py [dev\|docker\|production]` |
| `health_check.py` | System monitoring | `python scripts/health_check.py --detailed` |
| `security_scanner.py` | Security auditing | `python scripts/security_scanner.py all` |
| `model_manager.py` | ML model lifecycle | `python scripts/model_manager.py list` |
| `data_manager.py` | Data operations | `python scripts/data_manager.py validate` |
| `backup.py` | Backup & restore | `python scripts/backup.py full` |
| `log_analyzer.py` | Log analysis | `python scripts/log_analyzer.py errors` |
| `dev_utils.py` | Development tools | `python scripts/dev_utils.py test` |

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ†˜ Support & Community

### ğŸ“‹ **Important Documents**
- **ğŸ¤ [Contributing Guidelines](CONTRIBUTING.md)** - How to contribute to the project
- **ğŸ†˜ [Support Guide](SUPPORT.md)** - Getting help and reporting issues  
- **ğŸ”’ [Security Policy](SECURITY.md)** - Security vulnerability reporting
- **ğŸ’° [Funding](FUNDING.yml)** - Support the project development

### ğŸ“ **Get Help**
- **ğŸ“– Documentation**: Check the [docs/](docs/) directory
- **ğŸ› Bug Reports**: Use [GitHub Issues](https://github.com/Shizukaax/ndr-platform/issues)
- **ï¿½ Feature Requests**: Submit [enhancement requests](https://github.com/Shizukaax/ndr-platform/issues/new?template=feature_request.yml)
- **ğŸ’¬ Questions**: Ask in [GitHub Discussions](https://github.com/Shizukaax/ndr-platform/discussions)
- **ï¿½ Direct Contact**: justinchua@tunglok.com

## ğŸ‰ Acknowledgments

- **MITRE ATT&CK Framework** for threat intelligence taxonomy
- **Streamlit Team** for the excellent web framework
- **Scikit-learn Contributors** for machine learning capabilities
- **Open Source Community** for various dependencies and tools

---

<div align="center">

**â­ Star this repository if you find it useful!**

**ğŸ‘¨â€ğŸ’» Created by [Shizukaax](https://github.com/Shizukaax)**

</div>

## ğŸ“Š Usage Examples

### 1. Anomaly Detection Workflow
1. Navigate to **Anomaly Detection** page
2. Select data source and upload network data
3. Choose ML model (Isolation Forest recommended)
4. Click "Run Detection" - automatic analysis begins
5. View results with automatic MITRE mapping and risk scores

### 2. MITRE Mapping Analysis
1. Go to **MITRE Mapping** page
2. View automatically generated technique mappings
3. Explore risk scores and threat intelligence
4. Export analysis reports

### 3. Model Training
1. Access **Model Training** page
2. Upload labeled training data
3. Configure model parameters
4. Monitor training progress
5. Deploy trained models

## ğŸ” Data Sources

### Supported Formats
- **Network Captures**: PCAP files via Arkime
- **JSON Logs**: Structured security event data
- **CSV Files**: Tabular security data
- **Real-time Streams**: Live network monitoring

### Data Requirements
- Minimum 100 records for meaningful analysis
- Network flow data with source/destination information
- Timestamp information for temporal analysis
- Optional: Pre-labeled data for supervised learning

## ğŸ“ˆ Analytics Capabilities

### Statistical Analysis
- Descriptive statistics and data profiling
- Correlation analysis and feature importance
- Time series analysis and trend detection
- Outlier detection and anomaly scoring

### Machine Learning
- Unsupervised anomaly detection
- Supervised classification models
- Feature engineering and selection
- Model evaluation and validation

### Threat Intelligence
- MITRE ATT&CK technique mapping
- Risk assessment and scoring
- Threat actor attribution
- Attack pattern recognition

## ğŸ” Security Features

### Data Protection
- Secure data handling and storage
- Encryption for sensitive information
- Access control and authentication
- Audit logging and monitoring

### Privacy Compliance
- Data anonymization options
- GDPR compliance features
- Configurable data retention
- Secure data deletion

## ğŸ“ Configuration

### Main Configuration (`config/config.yaml`)
```yaml
# Application settings
app:
  name: "Network Security Analytics"
  debug: false
  log_level: "INFO"

# Model configuration
models:
  default_algorithm: "IsolationForest"
  auto_retrain: true
  performance_threshold: 0.8

# Security settings
security:
  enable_mitre_mapping: true
  risk_scoring: true
  notification_level: "WARNING"
```

### Environment Variables
```bash
# Optional environment configuration
STREAMLIT_SERVER_PORT=8501
LOG_LEVEL=INFO
DATA_PATH=/app/data
MODEL_PATH=/app/models
```

## ğŸš¨ Monitoring & Alerts

### Real-time Monitoring
- Live anomaly detection results
- System performance metrics
- Data quality indicators
- Model performance tracking

### Alert Configuration
- Configurable alert thresholds
- Multi-channel notifications
- Escalation procedures
- Alert suppression rules

## ğŸ§ª Testing

### Running Tests
```bash
# Run platform fixes validation
python tests/test_fixes.py

# Run logging configuration test
python tests/test_logging.py

# Run specific test modules (if pytest installed)
python -m pytest tests/test_fixes.py
```

### Test Coverage
- Unit tests for core services
- Integration tests for workflows  
- Platform fixes validation
- Logging system integrity
- Configuration completeness

## ğŸ“š Documentation

### Comprehensive Guides
- **docs/FIXES_SUMMARY.md** - Complete summary of critical fixes and improvements
- **docs/LOGGING_GUIDE.md** - Logging configuration and best practices
- **DEPLOYMENT.md** - Deployment instructions for all environments

### Quick Access
- **Architecture**: See project structure above
- **API Documentation**: Inline docstrings and type hints
- **Configuration**: Environment variables in `.env.example`
- **Troubleshooting**: Check `docs/` directory for detailed guides

## ğŸ“š API Documentation

### Core Services API
All core services follow consistent patterns:
- Singleton initialization
- Standardized error handling
- Comprehensive logging
- Type hints and documentation

### Component Integration
- Clean dependency injection
- Modular service architecture
- Event-driven notifications
- Stateless operations where possible

## ğŸ¤ Contributing

### Development Guidelines
- Follow PEP 8 style guidelines
- Include comprehensive docstrings
- Add unit tests for new features
- Update documentation for changes

### Code Structure
- Keep modules focused and cohesive
- Use dependency injection patterns
- Implement proper error handling
- Follow the established architecture

## ğŸ“„ License

[Add your license information here]

## ğŸ†˜ Support

For issues, questions, or contributions:
- Check existing documentation
- Review logs in `/logs` directory
- Use built-in error reporting
- Follow troubleshooting guides

---

**ğŸ“… Last Updated**: August 5, 2025  
**âœï¸ Maintained by**: [Shizukaax](https://github.com/Shizukaax)  
**ğŸ“§ Contact**: justinchua@tunglok.com
